package {{packageName}};

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.node.ObjectNode;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.net.URI;
import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.time.Duration;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.atomic.AtomicBoolean;

/**
 * Kafka consumer that processes Debezium CDC messages from the legacy PostgreSQL
 * database and transforms them into clean domain objects via the MeshQL REST API.
 *
 * Generated by Mesher.
 */
public class LegacyToCleanProcessor {
    private static final Logger logger = LoggerFactory.getLogger(LegacyToCleanProcessor.class);

    private static final Map<String, String> TOPIC_TO_API = Map.of(
{{#each model.entities}}
            "{{../model.prefix}}.public.{{legacyTable}}", "/{{cleanName}}/api"{{#unless @last}},{{/unless}}
{{/each}}
    );

    private final String kafkaBroker;
    private final String platformUrl;
    private final ObjectMapper mapper;
    private final HttpClient httpClient;
    private final AtomicBoolean running;
    private final IdResolver idResolver;

{{#each model.entities}}
    private final {{className}}Transformer {{camelCase cleanName}}Transformer;
{{/each}}

    private KafkaConsumer<String, String> consumer;
    private Thread consumerThread;

    public LegacyToCleanProcessor(String kafkaBroker, String platformUrl, IdResolver idResolver) {
        this.kafkaBroker = kafkaBroker;
        this.platformUrl = platformUrl;
        this.mapper = new ObjectMapper();
        this.httpClient = HttpClient.newHttpClient();
        this.running = new AtomicBoolean(false);
        this.idResolver = idResolver;

{{#each model.entities}}
{{#if isRoot}}
        this.{{camelCase cleanName}}Transformer = new {{className}}Transformer();
{{else}}
        this.{{camelCase cleanName}}Transformer = new {{className}}Transformer(idResolver);
{{/if}}
{{/each}}
    }

    public void start() {
        if (running.getAndSet(true)) {
            logger.warn("Processor already running");
            return;
        }

        consumerThread = new Thread(this::consumeLoop, "{{model.prefix}}-processor");
        consumerThread.start();

        logger.info("Started legacy processor");
    }

    private Properties consumerProps() {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBroker);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "{{model.prefix}}-processor");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true");
        return props;
    }

    public void stop() {
        running.set(false);
        if (consumer != null) {
            consumer.wakeup();
        }
        if (consumerThread != null) {
            try {
                consumerThread.join(5000);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }
        if (consumer != null) {
            consumer.close();
        }
        logger.info("Processor stopped");
    }

    private void consumeLoop() {
        try {
{{#each model.processingPhases}}
            // Phase {{phase}}: Process {{#each entities}}{{this}}{{#unless @last}}, {{/unless}}{{/each}}
            logger.info("Phase {{phase}}: Processing {{#each entities}}{{this}}{{#unless @last}}, {{/unless}}{{/each}}...");
            consumer = new KafkaConsumer<>(consumerProps());
            consumer.subscribe(List.of({{#each entities}}"{{../../model.prefix}}.public.{{this}}"{{#unless @last}}, {{/unless}}{{/each}}));
            drainTopic(consumer);
            consumer.commitSync();
            consumer.close();
{{#each cachePopulation}}
            idResolver.populate{{pascalCase this}}CacheFromGraphQL();
{{/each}}
            logger.info("Phase {{phase}} complete");

{{/each}}
            // Continuous consumption of all topics
            logger.info("Continuous consumption of all topics...");
            consumer = new KafkaConsumer<>(consumerProps());
            consumer.subscribe(List.of(
{{#each model.entities}}
                    "{{../model.prefix}}.public.{{legacyTable}}"{{#unless @last}},{{/unless}}
{{/each}}
            ));

            while (running.get()) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
                for (ConsumerRecord<String, String> record : records) {
                    try {
                        processRecord(record);
                    } catch (Exception e) {
                        logger.error("Error processing record from {}: {}", record.topic(), e.getMessage(), e);
                    }
                }
            }
        } catch (org.apache.kafka.common.errors.WakeupException e) {
            if (running.get()) {
                throw e;
            }
        } finally {
            logger.info("Consumer loop ended");
        }
    }

    private void drainTopic(KafkaConsumer<String, String> topicConsumer) {
        int emptyPolls = 0;
        while (running.get() && emptyPolls < 10) {
            ConsumerRecords<String, String> records = topicConsumer.poll(Duration.ofMillis(500));
            if (records.isEmpty()) {
                emptyPolls++;
            } else {
                emptyPolls = 0;
                for (ConsumerRecord<String, String> record : records) {
                    try {
                        processRecord(record);
                    } catch (Exception e) {
                        logger.error("Error processing record from {}: {}", record.topic(), e.getMessage(), e);
                    }
                }
            }
        }
    }

    private void processRecord(ConsumerRecord<String, String> record) throws Exception {
        String value = record.value();
        if (value == null || value.isEmpty()) return;

        JsonNode envelope = mapper.readTree(value);
        JsonNode payload = envelope.has("payload") ? envelope.get("payload") : envelope;

        JsonNode after = payload.get("after");
        if (after == null || after.isNull()) {
            logger.debug("No 'after' document (delete operation?), skipping");
            return;
        }

        // PostgreSQL Debezium: 'after' is already a JSON object (not double-encoded)
        if (after.isTextual()) {
            after = mapper.readTree(after.asText());
        }

        String topic = record.topic();
        LegacyTransformer transformer = getTransformer(topic);
        if (transformer == null) {
            logger.warn("No transformer for topic: {}", topic);
            return;
        }

        ObjectNode cleanData = transformer.transform(after);
        String apiPath = TOPIC_TO_API.get(topic);
        if (apiPath == null) return;

        String meshqlId = postToApi(apiPath, cleanData);

        // Register ID mappings for FK resolution
        if (meshqlId != null) {
{{#each model.entities}}
            if (topic.endsWith("{{legacyTable}}")) {
                String legacyId = after.has("{{legacyPrimaryKey}}") ? after.get("{{legacyPrimaryKey}}").asText() : null;
                idResolver.register{{className}}(legacyId, meshqlId);
            }
{{/each}}
        }
    }

    private LegacyTransformer getTransformer(String topic) {
{{#each model.entities}}
        if (topic.endsWith("{{legacyTable}}")) return {{camelCase cleanName}}Transformer;
{{/each}}
        return null;
    }

    private String postToApi(String apiPath, ObjectNode data) throws Exception {
        String body = mapper.writeValueAsString(data);

        HttpRequest request = HttpRequest.newBuilder()
                .uri(URI.create(platformUrl + apiPath))
                .header("Content-Type", "application/json")
                .POST(HttpRequest.BodyPublishers.ofString(body))
                .build();

        HttpClient noRedirectClient = HttpClient.newBuilder()
                .followRedirects(HttpClient.Redirect.NEVER)
                .build();

        HttpResponse<String> response = noRedirectClient.send(request, HttpResponse.BodyHandlers.ofString());

        if (response.statusCode() >= 200 && response.statusCode() < 400) {
            String location = response.headers().firstValue("Location").orElse(null);
            if (location != null) {
                String id = location.substring(location.lastIndexOf('/') + 1);
                logger.info("POST {} -> {} (id: {})", apiPath, response.statusCode(), id);
                return id;
            }
            logger.info("POST {} -> {}", apiPath, response.statusCode());
            return null;
        } else {
            logger.error("POST {} failed: {} - {}", apiPath, response.statusCode(), response.body());
            return null;
        }
    }
}
